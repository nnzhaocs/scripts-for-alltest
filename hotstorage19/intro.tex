\section{Introduction}
\label{sec:intro}

%
% Introduction structure:
%
% 1. Background, benefits, and popularity of containerization;
%
% 2. Background on container images and registry storage;
%    large number of images => high storage requirements for the registries;
%
% 3. Significant amount of unharvested duplication across images.
%    Traditional dedup cannot be applied directly - need to decompress
%    Even with decompression, things do not work well: perfomance overhead
%
% 4. Sift's idea
%
% 5. Evaluation: how and what we got
%


%?: ~\cite{slacker, 7158965, cntr}.
%?: ~\cite{dockerbook}.

%%%
% 1. Background, benefits, and popularity of containerization;
%%%

\emph{Container runtimes}, such as Docker~\cite{docker} and
\mbox{CRI-O}~\cite{cri-o}, leverage Linux kernel's namespaces~\cite{namespaces}
and cgroups~\cite{cgroups}
%to efficiently isolate processes and virtualize compute resources.
to effectively virtualize compute resources for applications.
%
Unlike the Virtual Machines (VMs) that implement hardware
virtualization~\cite{adams2006comparison}, containers running on the same
machine share the Operating System (OS) kernel, resulting in virtual
environments with significantly lower resource usage and startup
times~\cite{7819678}.
%
Further, containerization runtimes introduce portable self-contained \emph{container
images} and are surrounded by a rich ecosystem of technologies that automate and
accelerate application development, deployment, and
management~\cite{kubernetes}~\VT{cite more}.

Given the significant benefits of containers, it is not surprising that they've
seen a remarkable advancement in modern cloud environments and architectures
%
The wide spread of container is further fueled by the growing popularity of the
microservices design methodology~\VT{cite}, for which containers effectively
became an enabler.
%
All major cloud platforms endorse containers as core cloud deployment
technologies~\cite{googlecengine,azurec,ibmkube,awscont} \VT{and it is
predicted that in XXX there will be YYY and cite}


%%%
% 2. Background on container images and registry storage;
%    large number of images => high storage requirements for the registries;
%%%

%
% - Images structure
% - Storage of images at the registry side
% - High and growing quantity of images
%
An image of an application contains its executables 
along with all of the dependencies---other executables, libraries, configuration
and data files.
%
When building images with, e.g., Docker, each executed command
executed, such as \texttt{apt-get install}, forms a new \emph{layer} on top of
the previous one~\VT{cite Dockerfile}.
%
Docker leverages a COW (copy-on-write) file system which allows Docker to
instantiate containers quickly. 
%
%Utilizing COW also improves storage system efficiency~\cite{docker, UnionFS}.
%by minimizes I/O and the size of each of the subsequent layers.  because it
%leverages the pointers to the existing files.
%
%Copy-on-write file system also provides layering of containers, thus you can
%create a base container and then have another container which is based on the
%base container.
%
%Commands can be executed manually or automatically using Dockerfiles.


%
% Storing images at the registry side
%
Docker images are stored as a set of shareable and content addressable
\emph{compressed layer tarballs} and are distributed through a \emph{registry}
like Docker Hub~\cite{docker-hub}.
%
A Docker registry delegates the storage responsibility to different drivers
using a content addressable store API.
%
A layer is uniquely identified by a collision-resistant hash of its content and
so no duplicate layers are stored in a registry~\cite{docker-hub}.
%
The drivers interface with the \emph{backend storage systems} such as
\emph{local file systems} or \emph{Cloud storage systems} (\eg S3~\cite{s3},
Azure~\cite{azuredriver}, Swift~\cite{swift}, OSS~\cite{oss}, GCS~\cite{gcs}).
%
Cloud storage systems usually use \emph{replication} to maintain high availability and tolerate server failure~\cite{Bonvin:2010:SFS:1807128.1807162}.
%
Each layer can have multiple \emph{replicas}.


%
% High and growing number of images => storage requirements
%
As the container market grows rapidly, more and more images and layers are
built, \emph{replicated}, and stored in Docker registries.
%
This puts intense pressure on the availability and scalability requirements of
a Docker registry's backend storage infrastructure~\cite{5655241}. 
%
Scaling-out involves data migration between existing storage servers and new
storage servers, and even between existing storage servers for load balancing,
which is detrimental to performance.

%
%
% 3. Significant amount of unharvested duplication across images.
%    Traditional dedup cannot be applied directly - need to decompress
%    Even with decompression, things do not work well: perfomance overhead
%
%
Many cloud storage systems utilize deduplication to remove duplicate data and
improve storage allocation, resulting in effective scale-out and a significant
cost savings on hardware upgrades ~\cite{Ng:2012:PDD:2245276.2245361, 6753819,
5655241}.
%
As shown in deduplication analysis of $47$~TB ($167$~TB uncompressed) Docker
image/layer dataset downloaded from Docker Hub~\cite{dedupanalysis}, About
$97$\% of files across \emph{compressed layers} are duplicate files.
%
If decompression and file-level deduplication is applied on the dataset,
subil: citation needed half of the storage space can be saved.


%
\VT{In general, we need to say the decompression is needed first}
%
The challenge of applying deduplication on Docker registry is that
decompressing layers can have overheads besides the obvious
decompression/compression. 
%
After decompression and simple file-level deduplication, the unique files may
become scattered on multiple servers.
%
To restore a requested layer, the
layer's files would need to be first fetched from multiple servers then
compressed into a layer (to preserve transparency and avoid client-side API
modifications).
%
%and sent back to the client.
%
The extra network, I/O, and computation will slow down the response time for
retrieving (\texttt{pulling}) an image.

%
%
% 4. Sift's idea
%
%
In this paper, we propose \sysname, a layer deduplication aware Docker registry
that provides significant storage improvements over standard registry
deployments while maintaining a good performance.
%
To do this, \sysname first
exploits two kinds of redundancies: redundant data among layers, and redundancy
policy used by Cloud storage system.
%
\sysname maintains a certain number of
\emph{layer replicas} for layer accesses while \emph{deduplicates} the rest
\emph{layer replicas} into \emph{unique files} to save space.
%
In this case, by
deduplicating different number of layer replicas, \sysname provides different
\textbf{basic deduplication modes} to meet different capacity and performance
requirements while maintaining the same failure-tolerance ability.
%
Besides,
\sysname also provides \textbf{selective deduplication mode} to deduplicate a
certain number of layer replicas inversely proportional to their
\emph{popularity} to achieve significant space savings while maintaining a good
performance.
%
Moreover, \sysname also explores user access patterns and
preconstructs layers before \texttt{pulling} layer requests arrive to save
layer restoring latency.
%
Finally, \sysname does not just simply uses
decompression and file-level deduplication to remove duplicate files from layer
dataset.
%
\sysname \emph{splits} a layer into \textbf{slices} during layer
deduplication to enable \emph{parallel streaming layer construction} for fast
layer restoring performance.


%
%
% 4. Sift's evaluation
l
%
We implemented and deployed \sysname on a 21-node cluster and evaluated with
real-world workloads and real layers.
%
The evaluation results show that
uses a cache that takes into consideration the user behavior and layer
popularity, in addition to parallelizing layer construction across %HA?
servers.

%This paper is organized into the following sections: Section 2 talks about
%observed behaviors and access patterns in Docker registries, Section 3 covers
%the design of our registry, Section 4 details the implementation of the
%registry, Section 5 evaluates the performance of the registry, Section 6 talks
%about similar work done in the field, and Section 7 concludes. 
