
\subsection{Caching layers}
\label{sec:cache-design}

%In the following, we present our \sysname~\preconstructcachename design.
%Each \texttt{pull layer} request has a precedent \texttt{pull manifest} request.
%Upon receiving a \texttt{pull manifest} request, 
%\sysname~sends the updated \sysname~manifest to client.
%After receiving a \sysname~manifest, the client parses the manifest
%and sends either a \texttt{pull layer} request if the layer hasn't been deduplicated,
%or a list of \texttt{pull slice} requests if a list of corresponding slices presents in the manifest.
%Those \texttt{pull slice} requests will then be
%forwarded to all the registry servers that store the requested
%layer's slices as shown in Figure~\ref{fig:sys-overview}. 

%\input{fig-layer-preconstruct}

%\LR{Why are we calling it `superfetch cache'? Isn't that just a prefetch cache?}

\sysname maintains a cache layer in both the primary and deduplication clusters to speed up
\texttt{pull} requests. The primary cluster cache (also called \emph{superfetch cache}) is
memory-based to avoid disk I/O during layer retrievals while the deduplication cluster cache
(also called \emph{preconstruct cache}) is on disk. The main purpose of the preconstruct
cache is to store preconstructed layers, which are likely to be accessed in the future,
to avoid the layer restoring overhead.
%
Both caches are filled based on the user access patterns observed in Section~\ref{sec:dataset-analysis}.
%\LR{Describe the interaction between the caches. Are they independent and make their
%own predictions. Are they always making the same predictions? How large are they?}
%\NZ{Yes, they have the same prediction module to do layer prediction and  share the metadata ULmap and RLmap.
%But the two cache wont do prediction at the same time.
%Either of them can do prediction and update the maps.}
%\LR{This is unclear, wouldn't the P-servers always update ULmap and RLmap because every request first goes
%to them? When is a prediction triggered? Only on GET manifest?}
%
%\sysname predicts what layers will be accessed and 
%prepares the layers before \texttt{pull} layer requests.
%To improve the performance of primary cluster,
%\sysname \emph{superfetches} the layers that will be accessed later into \textbf{superfetch cache}.
%Moreover,  to improve the layer restoring performance of deduplication cluster,
%\sysname preconstructs layers before \texttt{pull} layer requests 
%and put them into \textbf{preconstruct cache} to save restoring latency.

\paragraph{Request prediction}
%
%\LR{The following paragraph should be part of the background. By now,
%the reader should be familiar with the pull process.}
%
%Typically, when a user 
% \texttt{pulls} an image,
%it will first \texttt{pulls} the image's manifest and extract the image's layers from the manifest, 
%Next, it compares these layers against a \emph{local layer index}.
%If a layer isn't presents in the \emph{local layer index}, meaning the layer hasn't been stored locally,
%the user will \texttt{pull} the layer.
%Otherwise, the user will start pulling the layer.

%Based on the above access pattern,
To accurately predict layers that will be accessed in the future, \sysname keeps
track of user access patterns and image metadata.
Therefor, it uses two maps to record the image-to-layer information
and user layer accesses: RLmap and ULmap.
%
\LR{Change RLmap (repo-to-layer) to ILmap (image-to-layer)?}
%\NZ{Repo to layers; User to Layers.}
%
%\LR{ Is the layer set the set of layers contained in an image? Why do we need
%an extra map for this? Can we also get this from the manifest? Need to explain
%the reasoning here.}
%\NZ{It takes a long time to load manifest for each request.}

RLmap maps an image to its containing \emph{layer set} and an entry in RLmap
is identified as \textless{}Repository name@manifest digest\textgreater.
%
%Layer is identified as layer digest.
%
ULmap stores for each user, the layers the has user accessed and the corresponding pull count.
A user is uniquely identified by extracting the sender network address from the request.
%
Both maps serve as fast indices to speed up the prediction process.

When a \texttt{GET manifest} request $r$ is received,
\sysname first calculates a set of image layers that haven't been pulled by the user $r.addr$ 
by calculating the difference $S_{\Delta}$ between the image's layer set and the user's accessed layer set
%
\begin{equation*}
S_{\Delta} = RLmap[r.img] - ULmap[r.addr].
\end{equation*}
%
The resulting layers in $S_{\Delta}$ are likely going to be accessed later.

Recall from \S\ref{sec:predictable-user-access} that some users \emph{always} pull
layers, no matter if the layers have been previously pulled. To detect such users,
\sysname first gets the subset, $S_{\cap}$, of layers from the image that have already
been pulled by the user by computing
%
\begin{equation*}
S_{\cap} = RLmap[r.img] \cap ULmap[r.addr].
\end{equation*}
%
Next,  \sysname compares the client repull probability 
$\gamma[r.addr]$ with a predefined client repull threshold $\varepsilon$.
If $\gamma[r.addr] > \varepsilon$, then \sysname classifies the user as a repull user
and fetches the layers in $S_{\cap}$ into the cache.
%
%\LR{Here, we need to talk more about how we get the repull probability and how we
%maintain it over time. Do we assume a static one like dicussed in background or
%are we updating it for each client over time?}
%\NZ{We calculate the repull proabability as the total number of pull layer request divided by the number of
%it accessed layers.
%We maintain each layer's pull count for a user in ULmap.
%So we can calculate the repull probability during each prediction.}

The repull probability is computed based on ULmap. More specifically, for each
\texttt{GET manifest} request $r$, \sysname will compute the repull probability for a user
$r.addr$ as
\begin{equation*}
\gamma[r.addr] = \sum_{l \in RL} l.pullCount /  \sum_{l \in L} l.pullCount
\end{equation*}
where $RL$ is the set of layers that the user has repulled before, i.e. with a pull count greater
than $1$, and $L$ is the set of all layer the user has ever pulled. \sysname updates the pull
counts for a user whenever a \texttt{GET layer} request is received.
%
%targets $\leftarrow$ difference \\
%\ForEach{layer in intersection} 
%{ \If{ layer.rpcnt $>$ $\theta_{rpc}$}{
%		targets	$\leftarrow$ layer
%	}
%}

\paragraph{Cache handling in tiered storage} 
%As mentioned earlier, \sysname uses two-tier storage architecture: primary cluster
%and deduplication cluster. Now with the adding of superfetch cache and preconstruct
%cache, The two-tier storage architecture becomes multiple-level storage architecture
%as shown in Figure~\ref{fig:tieredstore}.

%\LR{We need to provide more details on how we search the different tiers.
%Do we keep an index for each tier? How fast are the searches?}
%\NZ{Layer index holds the server address for each layer replica.
%	If the server is a P-server, then it's a layer replica stored in tier 1.
%	Otherwise it is deduplicated and stored in tier  2.
%Similar as files, we dont maintain layer path because each layer is stored in directory
%‘rootdir/docker/registry/v2/blobs/sha256/< first two hex bytes of layer digest >/<hex layer digest>/’ 
%(denoted as layerdir) as a file named ‘data’.}

The introduction of the two cache layers results in a 5-tier storage architecture of
\sysname as shown in Figure~\ref{fig:tieredstore} \Subil{We say 5-tier here but 2-tier in the figure. Must change one or the other for consistency along with any other mentions of 2-tier/5-tier in the paper}. Requests are passed through the
tiers in the order displayed in the figure. Upon a \texttt{GET} layer request,
\sysname first determines the P-server(s) which is (are) repsonsible for the layer
and searches the superfetch cache(s).
If the layer is present the request will be served from cache.
Otherwise, the request will be served from the layer store .
%\texttt{prefetches} layers on primary cluster based on the above user request prediction theory.
%After P-servers receive the primary layer replicas,
%\sysname will save the layer replicas into \emph{superfetch cache} as shown in Figure~\ref{fig:sift}.
%Meanwhile, it updates \emph{RLmap} with the layer and its associated image. 

If a \texttt{GET} layer request can't be served from the primary cluster
due to a failure of the corresponding P-server(s),
the request will be forward to the deduplication cluster.
In that case, \sysname will first look up the layer recipe. If not found, it means that
the layer has not been fully deduplicated yet and \sysname will serve the layer
from one of the layer stage areas of the responsible D-servers. Those are located
through consistent hashing.
If the layer recipe is present, \sysname will contact the restoring master to
check, whether the layer is in its preconstruct cache. Otherwise, it will
instruct the restoring master to rebuild the layer.

Both the superfetch and the preconstruct cache are write-through caches.
When a layers is evicted, it will simply be discarded since it does not contain any
updates to layers.
%Recently uploaded layers, which are temporarily stored in the
%layer stage area will be evicted to the preconstruct cache after the layer is
%deduplicated.
%
We use Adaptive Replacement Cache (ARC) replacement policy~\cite{megiddo2003arc}, which keeps track of both the frequently and recently used layers and adapts to changing access patterns.
\LR{Add details on on what ARC does exactly. How does it adapt? Why did we choose ARC?}
%For preconstruct cache, it's possible when a \texttt{pull} layer request comes 
%before layer restoring is finished, meaning the layer cannot be preconstructed \emph{on time}.
%In this case, \texttt{pull} layer request \emph{waits} until the restoring is finished
%(detailed in Section~\ref{sec:impl}).
%
%When a~\texttt{pull} layer request is received, 
%\sysname will first search superfetch cache for the request layer.
%If the layer presents in cache, the request will be served from cache.
%Otherwise,
%the request will be served from layer store.
%Meanwhile, it updates \emph{ULmap} with the request sender and its associated layer. 

%ULmap records user access status,
%which maps a \textbf{user Id} to its accessed layers with its corresponding access count,
%where user id is defined as client request address.

%
%\paragraph{Preconstruct cache on deduplication cluster}
%%\input{preconstruct_algori.tex}
%To improve layer restoring performance,
%\sysname \texttt{preconstructs} layers before \texttt{pull} layer requests to save layer construction time.
%Upon each \texttt{pull} manifest request,
%\sysname will predict a \emph{target layer set} that will be requested later based on above prediction theory.
%%
%%Meanwhile,
%%\sysname will update \emph{RLmap} with the layer and its associated repository, where
%%RLmap maps a \textbf{repository id} (i.e., repository name) to its containing layers 
%%as shown in Figure~\ref{fig:dedup-partition}.
%After that,
%\sysname gets each layer's layer recipe from metadata database
%and extracts each layer's restoring master.
%Next,
%\sysname sends a notification of \texttt{preconstruct layer} to
%each restoring master.
%After receiving the notification, 
%the restoring master starts layer restoring process and stores the preconstructed layer into \emph{preconstruct cache}.
%
%When a~\texttt{pull} layer request is received, 
%\sysname will first search requested layer from preconstruct cache.
%If the layer presents in cache, the request will be served from cache.
%Otherwise,
%\sysname will rebuild a layer from file store.


%(detailed in Section~\ref{xxx}).
 
%the request will be served from layer store.
%\sysname will first update \emph{ULmap}. 
%ULmap records user access status,
%which maps a \textbf{user Id} to its accessed layers with its corresponding access count,
%where user id is defined as client request address.

%Figure~\ref{fig:preconstruct}
%shows how to preconstruct layers for later accesses.
%When a \texttt{GET manifest} request is received by registry $A$,
%it gets the requested repository information and client information from RLmap and ULmap respectively, 
%and computes a list of target layers that will be accessed later by this client.
%As shown, to preconstruct target layer $L1$, 
%registry $A$ gets $L1$'s layer recipe from metadata database
%and sends a notification of \texttt{preconstruct layer} $L1$ to 
%$L1$'s restoring master: registry $B$. 
%After receiving the notification, 
%$B$ sends \texttt{get slice} requests to its peer workers: $C$ and $D$.
%When $B$, $C$, and $D$ finished slice constructions for $L$,
%three slices are concatenated by $B$ and saved in $B$'s layer diskcache. 


%
%Algorithm~\ref{alg:prefetch} shows how to determine target layers 
%based on observed user access pattern.
%When a \texttt{GET manifest} request \emph{r} is received,
%\sysname~gets a set of layers associated with the requested repository \emph{r.repo} from RLmap, 
%denoted as $RLmap[r.repo]$.
%Meanwhile, it also gets a set of layers associated with the client \emph{r.client} from ULmap,
%denoted as $ULmap[r.client]$.
%After that, it calculates a list of layers in the requested repository 
%that have not been \texttt{pulled} by the client by
%computing the difference set between $RLmap[r.repo]$ and $ULmap[r.client]$ (denoted as $difference$).
%All the layers in $difference$ are included in target set.
%\sysname also calculates a intersection set between 
%$RLmap[r.repo]$ and $ULmap[r.client]$ (denoted as $intersection$).
%The layers in $intersection$ are already pulled by client.
%To determine whether a layer in $intersection$ will be
%$repulled$ by client,
%\sysname compares its repull count against a predefined threshold $\theta_{rpc}$.
%If the layer's repull count is greater than $\theta_{rpc}$,
%which means this layer will be repulled with high probability.
%Thus, it is included in target layer set.

%After D-servers receive the backup replicas,
%\sysname will first update \emph{RLmap} with the layer and its associated repository, where
%RLmap maps a \textbf{repository id} (i.e., repository name) to its containing layers 
%as shown in Figure~\ref{fig:dedup-partition}.

%
%For each layer in target set, 
%\sysname gets the restoring master from its layer recipe,
%and sends a notification of \texttt{preconsturct layer} to the master.
%After the master receives the notification,
%it first checks if the requested layer is in the preconstruct cache.
%If not, 
%it starts layer construction and saves the preconstructed layer in the preconstruct cache.
 
%and gets two groups of layers: \emph{newLayers} and \emph{oldLayers}.
%\emph{newLayers} means the layers that belongs to \emph{r.repo} but haven't been pulled by client \emph{r.client}.
%While \emph{oldLayers} means the layers that belongs to both of them.
%\preconstructcachename~will first restore the slices for \emph{newLayers} because 
%they are not locally available to \emph{r.client}.    
%For \emph{oldLayers}, 
%if an \emph{oldLayer} has a higher repull count and \emph{r.repo} as well as \emph{r.client} have a higher repulling probability,
%then \preconstructcachename~will restore its slices and cache them.
%If a \emph{PUT} layer request is received, RLmap and URLmap will be updated accordingly.
%
%If a \emph{GET} layer request is received, it means that \emph{r.layer} has not been deduplicated.
%\preconstructcachename~will cache \emph{r.layer} if cache miss happens on \emph{GET} layer request as shown in Algorithm~\ref{alg:prefetch}.
%If a \emph{GET} slice request is received, meaning that \emph{r.layer} has already been deduplicated into deduplicated slices,
%\preconstructcachename~will check if the requested \emph{r.slice} exists in the cache.
%If not,
%\dedupname system~will start restoring \emph{r.slice} and also put it in cache.
%In the end, \preconstructcachename~will update URLmap with corresponding repull count and repull probability.
%\paragraph{Preconstruct cache eviction}
%To exploit the temporal trend of clients and repositories, 
%\sysname sets timer for each cached layers.
%Once a layer is expired,
%it will be simply deleted from the preconstruct cache.
%
%Preconstruct cache replacement is triggered when the free space in the cache is
%lower than threshold $\theta_{C}$.
%As shown in Algorithm~\ref{alg:eviction}, 
%\sysname~maintains a LFRU list~\cite{xxx} of cached layers to exploit 
%layer temporal trend.
%If the free space is low,
%\sysname~selects the least frequent recently used layer to evict.


%\input{eviction_algori}

%\input{fig-repull-analysis}





