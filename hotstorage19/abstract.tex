\begin{abstract}

%We did a deduplication analysis on around 50TB compressed image dataset and found that we can save about half of the storage space by doing file-level deduplication after decompressing all the images. However, deduplication affects Docker registry's performance especially for pulling performance because restoring layers require fetching files and compressing them into layers. To reduce deduplication restoring overhead(i.e., decompress/compression and additional networking and I/O), we propose a novel architecture that integrates compressed file-friendly deduplication and container user-friendly caching. 

 Container virtualization has become the de-facto standard 
for deploying modern applications because 
of its lightweight, tight isolation, and low overhead. 
However,
the rapidly increasing number of container images presents great challenges on Docker registry that already holds millions of container images.
We performed a large-scale deduplication analysis on 47 TB (167 TB uncompressed) dataset, and find
only 3\% of files are unique and the rest are duplicate files, 
suggesting that current layer-level content addressable 
mechanism is insufficient for Docker registry. 
Despite the large deduplication potential, current deduplication techniques 
are not compatible with registry dataset: compressed layers.
Directly applying them on registry will
 suffer from either low deduplication ratio or large overhead. 
%This problem has so far remained largely unexplored.
% 
In this paper, we propose a new Docker registry architecture, \sysname,
that integrates caching and deduplication with Docker registries to 
help reduce the storage requirements while mitigating any performance overhead.
\sysname uses a user access history-based prefetch algorithm to accurately 
prefetch the layers that will be accessed shortly,
and a two two-tier heterogeneous cache to improve cache space efficacy.
Our evaluation of the user access history-based prefetch algorithm yields a hit ratio of 96\%. 
Even more, our two-tier heterogeneous cache architecture, allows 56\% more layers into the file cache.
%Based on our 

%sustaining and scaling container systems in the face of exponential growth is challenging. 
%%
%For example, Docker Hub~\cite{docker-hub}---a popular public container registry---stores more than~2 million public repositories. These repositories have grown at the rate of about $1$ million annually---requiring provisioning an additional 2.5~TB of storage per week on average---and the rate is expected to increase.
%%
%This puts intense pressure on Docker registry storage infrastructure, but the problem has so far remained largely unexplored.
%


\end{abstract}

%we predict  
%Overall,  
%to model the deduplication for estimating the deduplication effect on performance and storage savings, especially in terms of deduplication rate and deduplication overhead. We propose to use Markov decision process to find optimal solution that can maximize the storage saving and minimizing the cost in terms of performance degradation. Our solution will largely reduce the amount of redundant data in container storage systems and outperform the state-of-art deduplication techniques without any performance overhead.

%and evaluate
%the potential of file-level deduplication in the registry.
%
%Our analysis reveals that 
%
%We then present the design of \sysname---a Docker registry with file deduplication
%support---and conduct a simulation-based analysis of its performance implications.