\subsection{Methodology}
\label{sec:methodology}

%\input{tab-dataset-summary.tex}

To analyze the benefits of different data reduction techniques for the Docker registry,
we downloaded a large number of Docker images.
%
We chose the Docker Hub registry~\cite{docker-hub} as our source of images
due to its popularity and its significant number
of public repositories.
%
We expect that because of these reasons, our findings are applicable to other
registry deployments.

Docker Hub does not provide an API to retrieve all repository names.
Hence, we crawled the registry's website to obtain a list of all available
repositories, and then downloaded the \emph{latest} version of an image and its
corresponding layers for each repository.
% over a period of 30 days.
%
We plan to extend our analysis to other image tags in the future.
%
We downloaded 355,319 images, resulting in 1,792,609 compressed layers
and 5,278,465,130 files, with a total compressed dataset size of 47\,TB.
%
%
To store and analyze the data, we deployed an 8-node Spark~\cite{spark}
cluster with HDFS~\cite{hdfs} as the backend storage.

%
%Specifically, there are two steps: i)~crawl Docker Hub web pages to list all
%repositories; ii)~download the \textit{latest} image (and referenced layers)
%from each repository based on the crawler results.
%
%Here, we chose latest image from each repository because (1)~the ``latest''
%version is usually the newest, stable, and commonly pulled by developers;
%(2)~downloading only the ``latest'' version can shorten our downloading
%process since the latest images already took about 30 days to download.
%
%
%\VT{make sure we introduce the concept of ``tag'' in earlier section}
%\NZ{addressed}
%
%\paragraph{Web crawler}
%
%Public repositories in Docker Hub are divided into official
%repositories---served by the Docker Hub partners---and non-official
%repositories---provided by regular users and third-party organizations.
%%
%The number official repositories is less than 200, while, the majority of
%repositories in Docker Hub are non-official (over 400 thousand).
%%
%To list non-official repositories, our crawler utilizes the Docker Hub
%web-based search engine to find all available repositories.
%%
%As the name of non-official repositories is comprised of the user name and the
%repository name separated by a ``/'', we can search for ``/'' and obtain a
%list of all non-official repositories.
%%
%The Crawler downloads all pages from the search results and parses the web
%content to build a list of all non-official repositories.
%%
%We ran the crawler on May 30th, 2017 and it produced a list of 634,412
%repositories.
%%
%After removing duplicate entries (introduced by Docker Hub indexing logic),
%the final repository list consists of 457,627 distinct repositories.
%
%\paragraph{Downloader}
%
%Instead of using the Docker client to download images, we implement our own
%downloader, which calls the Docker registry API
%directly~\cite{dockerregistryclient} to download manifests and image layers in
%parallel.
%%
%Our downloader runs significantly faster than a \texttt{docker pull}-based
%downloader because the latter one performs other operations besides
%downloading the image, such as unpacking the layers and creating the
%corresponding read-only snapshots.
%%
%Our downloader can download multiple images simultaneously and fetch the
%individual layers of an image in parallel.
%%
%Layers are transferred as gzip compressed tar archives.

%Specifically, we downloaded 355,319 images,
%resulting in 1,792,609 compressed layers and 5,278,465,130 files,
%with a total dataset capacity of 47~TB.
%
%Table~\ref{tab-dataset-summary} summarizes the properties of the downloaded
%dataset.
%
%\LR{Maybe remove the table entirely, now that it only has a single row and all
%numbers are mentioned in the text above.}\NZ{addressed}
%
%\VT{What about leaving the Table instead but remove the text?}
%
