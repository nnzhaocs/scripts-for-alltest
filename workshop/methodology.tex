\subsection{Methodology}
\label{sec:methodology}

\input{tab-dataset-summary.tex}

%In this section we describe our methodology for obtaining a representative Docker image dataset.
%%
%(1)~obtaining a representative Docker image dataset, and
%%
%(2)~analyzing basic and deduplication properties of the dataset.
%
%%\input{fig-downloader-analyzer.tex}
%
%\subsection{Dataset acquisition}
%\label{sec:crawler}

To analyze the benefits of layer- and file-level deduplication for Docker registry
and identify the main sources of data redundancy, we downloaded a large number of
Docker images.
%
We chose the Docker Hub~\cite{docker-hub} registry as a source of the images
because it is popular among developers and contains many public repositories.
%
Due to its popularity, we believe the Docker Hub dataset is representative for
other registry deployments.

Docker Hub does not provide an API to retrieve all repository names.
Hence, we crawled the registry to obtain a list of all available repositories
and then downloaded the \emph{latest} image and the corresponding layers for
each repository.
%
%\VT{Nannan, avoid using passive voice in the sentences. E.g., above, instead of
%``is needed`` you can say ``we used web crawlig to...``. Please, check the
%whole text for passive voice and change where applies.}
%\NZ{addressed}
%
%Specifically, there are two steps: i)~crawl Docker Hub web pages to list all
%repositories; ii)~download the \textit{latest} image (and referenced layers)
%from each repository based on the crawler results.
%
%Here, we chose latest image from each repository because (1)~the ``latest''
%version is usually the newest, stable, and commonly pulled by developers;
%(2)~downloading only the ``latest'' version can shorten our downloading
%process since the latest images already took about 30 days to download.
%
We plan to extend our analysis to other image versions in the future.
%
%\paragraph{Web crawler}
%
%Public repositories in Docker Hub are divided into official
%repositories---served by the Docker Hub partners---and non-official
%repositories---provided by regular users and third-party organizations.
%%
%The number official repositories is less than 200, while, the majority of
%repositories in Docker Hub are non-official (over 400 thousand).
%%
%To list non-official repositories, our crawler utilizes the Docker Hub
%web-based search engine to find all available repositories.
%%
%As the name of non-official repositories is comprised of the user name and the
%repository name separated by a ``/'', we can search for ``/'' and obtain a
%list of all non-official repositories.
%%
%The Crawler downloads all pages from the search results and parses the web
%content to build a list of all non-official repositories.
%%
%We ran the crawler on May 30th, 2017 and it produced a list of 634,412
%repositories.
%%
%After removing duplicate entries (introduced by Docker Hub indexing logic),
%the final repository list consists of 457,627 distinct repositories.
%
%\paragraph{Downloader}
%
%Instead of using the Docker client to download images, we implement our own
%downloader, which calls the Docker registry API
%directly~\cite{dockerregistryclient} to download manifests and image layers in
%parallel.
%%
%Our downloader runs significantly faster than a \texttt{docker pull}-based
%downloader because the latter one performs other operations besides
%downloading the image, such as unpacking the layers and creating the
%corresponding read-only snapshots.
%%
%Our downloader can download multiple images simultaneously and fetch the
%individual layers of an image in parallel.
%%
%Layers are transferred as gzip compressed tar archives.

Overall, we downloaded 355,319 images, which consist of a total of 1,792,609
compressed layers and 5,278,465,130 files, resulting in a total dataset
of 47~TB
%A total of 111,384 images could not be downloaded mainly
%because they did not have the \texttt{latest} tag.  
The downloading process took about 30 days.
%
%\vcomment{Say just one sentence why we did not download some
%images.}\nancomment{Addressed}
%
Table~\ref{tab-dataset-summary} summarizes the properties of the downloaded
dataset.
%
\LR{Maybe remove the table entirely, now that it only has a single row and all
numbers are mentioned in the text above.}
%
%\VT{Let's not go into details in the table and in the text how many images we
%downloaded but did not analyze, or how many we could not download, etc.  Let's
%just state the total number of images/repos/layers we finally analyzed and
%their sizes and file numbers.}
%\NZ{addressed}
%
To store and analyze the data, we deployed an 8-node Spark~\cite{xxx}
cluster with HDFS~\cite{xxx} as a backend storage system.
%
%\VT{Maybe mention a sentece or two that we used SPARK cluster to do the
%analysis?}
%\NZ{addressed}

