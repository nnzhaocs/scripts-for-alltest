\section{Introduction}

Because of their lightweight isolation and fast deployment,
\emph{containers}~\cite{process-containers-linux} have recently gained a
significant traction.
%
Polls suggest that 87\% of enterprises are at various stages of adopting
containers, and they are expected to constitute a lucrative \$2.5 billion
market~\cite{container-grow-by2020} by 2020.

Docker combines process containerization with efficient and effective packaging
of complete runtime environment in so called {\em images}.
%
Images are composed of shareable and {\em content addressable layers}.
%
Each layer is essentially a set of files that 
are compressed in a single archive.
%
Both images and layers are stored in Docker registry and accessed by clients as
needed.
%
Since layers are uniquely identified by using collision-resistant hash of the
content, no duplicate layers are stored in Docker registry.

Currently, registry is growing rapidly.
%
For example,   Docker Hub~\cite{docker-hub}, the most widely used registry,
stores more than 500,000 public image repositories comprising of over 2 million
layers.
%
The size of the registry continues to steadily increase---we observed a
linear growth of the number of images in Docker Hub over a period from June to
September 2017, with an average creation rate of 1,241 repositories per day.
%
%(as shown in Figure~\ref{fig_image_growth}.
%
This massive image dataset that presents challenges to the registry storage
infrastructure has remained a largely unexplored area.

In this paper, we performed the first, in-depth, large-scale redundancy
analysis of the images and layers stored in the Docker Hub
registry~(\S\ref{sec:background}).
%
We downloaded 51TB worth of Docker Hub images which contains over 5 billion (167 TB)
of files after decompression.
%
%We started our analysis
%with collecting all the metadata over xxx images and  conducted the first
%comprehensive characterization of the image dataset (or union file systems). This analysis is particularly useful as no prior work exists on union file
%systems~\cite{xxx} and dataset used and created exclusively for Docker,
%which are different from either analysis on EX4 linux file system~\cite{xxx} or
%Windows file system~\cite{xxx}.
%%
%%We not only present the distribution for each metric but also pointed out the
%%challenges faced by Docker engine designer and registry designer based on
%%global knowledge (or analysis) of metadata. 
%We also provide useful insights (parameters or metrics)
%for the developers to better
%understand the file systems used by Docker container. 
%
%%Unfortunately, it's unknown whether  this coarse-grain layer-level content
%%addressable storage (LLCAS) can efficiently reduce duplicates, and how much
%%redundant data is stored in layer, image, and registry because there is no
%%prior research on registry dataset analysis.
%
%We continued with the deduplication analysis of the dataset.
%
Surprisingly, we found only around 3\% of the containing files are unique files
while others are redundant copies, which means that current layer-level content
addressable storage cannot efficiently reduce duplicates.
%
To inspect what are the redundant files and why there are so many redundant
files, we conducted a comprehensive redundancy analysis on the 167 TB
uncompressed dataset.
%
We made three major observations.
%
\begin{compactitemize}
%
\item Only 10\% of layers are referred by more than one images, 
meaning that layer-level content addressability is not efficiently utilized by Docker registry.
%
\item A large amount of full file duplicates are shared cross layers and cross images. 
Only 3\% of files in the uncompressed layer dataset are unique files while others are redundant file copies.
%
\item Majority of the file duplicates are executables and object files, which are mostly created by the source code duplicates.
%
We found that different Docker developers are prone to replicate same source codes from external public repositories (e.g., GitHub~\cite{xxx}) and store these source code duplicates cross layers because there is no official images available for pulling.  

\end{compactitemize}

Finally, we proposed a file-level content addressable storage model (FLCAS) for Docker registry, which utilizes file-level deduplication to remove redundant files. 
%
We simulated FLCAS for 0.9 million layers and provided different suggestions to improve deduplication performance. The simulation result shows that (1) processing layers in parallel can largely improve throughput. For example, 80\% of file-level deduplication time is
less than 9.09 s per layer and by processing 60 layers in parallel, our one-node file-level deduplica-
tion prototype can process about 3 layers per second.
(2) Fast compression methods can mitigate pulling overhead caused by re-compression  because files are required to be re-compressed as a compressed layer archival file to serve the incoming pulling requests.


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%                                                                            %
%                                OLD INTRO                                   %
%                                                                            %
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%Finally, we proposed and implemented Docker registry design that performs
%deduplication.
%%
%In our thorough redundant analysis and characterization of the xxxx images,
%with xxxx layers and xxxx files, we investigated the following four research
%questions (RQs):
%
%\begin{compactitemize}
%%
%\item How much redundant data stored in layers, images, and registry? Although
%layer-level address content addressable storage is adopted by Docker, we do not
%know whether  this coarse-grain layer-level content addressable storage (LLCAS)
%can efficiently reduce duplicates, and how much redundant data is stored in
%layer, image, and registry.
%%
%\item What are the redundant files and why there are so many redundant files?
%We aim to identify what are the redundant files that users mostly replicate.
%%
%Such information will provide Docker designer knowledge (user behavior) to
%better develop and optimize Docker container and Docker registry storage
%system.
%%
%\item What are the challenges faced by Docker registry and engine designer? By
%characterizing and analysis all the image metadata, we aim to identify the
%challenges' faced by registry designer and guide designers'optimization and
%users' development.
%%
%\item How to reduce the redundant files? We aim to propose a file-level content
%addressable model to reduce the redundant files by using file-level dedup while
%maintaining a good performance.
%%
%\end{compactitemize}
%
%The significance of this work are (1) our empirical evidence that large amount
%of redundant files exist in layers, images, and registry and layer-level
%content addressable storage is not efficient to remove redundant files;(2)
%findings about what are the redundant files and why there are so many redundant
%files exist;(3) first in-depth characterization on image dataset (union file
%systems)(4) a file-level content addressable model that can efficiently remove
%redundant copies while maintain a good performance.

%For years, virtual machines served as a cornerstone of computing resource
%virtualization both on premises and in the cloud~\cite{rosenblum2005virtual}.
%%
%Recently, however, \emph{container-based} virtualization started to gain
%significant traction~\cite{process-containers-linux}.
%%
%According to polls, over 87\% of enterprises are at various stages of adopting
%containers; analysts also predict that by 2020, containers will constitute a
%lucrative \$2.5 billion market~\cite{container-grow-by2020}.
%
%
%
%At its core, container is a set of processes which are isolated by the operating
%system kernel in terms of visibility and resources. This allows containers to share
%the same kernel without being aware of each other.
%%
%For example, Linux performs visibility isolation (for user identifiers, file systems,
%network, etc.) using namespaces~\cite{man-namespaces} and enforces resource
%utilization constraints with control groups~\cite{kernel-doc-cgroups}.
%%
%Compared to virtual machines, containers use less memory and storage, are much
%faster to start, and typically cause less execution
%overhead~\cite{felter2015updated, Disco, HypervisorsvsLightweight}.
%
%The rapid increase in use of container technology was largely made possible by
%container management frameworks, with Docker being one of the most popular
%solutions~\cite{docker}.
%%
%Docker combines process containerization with efficient and effective runtime
%environment packaging.
%%
%Software is packaged in container \emph{images}, each consisting of several
%read-only \emph{layers} and a manifest which describes container metadata, \eg
%what layers make up an image and which command to run at container startup.
%%
%Read-only layers can be shared between different images and encapsulate
%file-system trees for dockerized processes.
%
%%Docker is another technology whose popularity grew rapidly in the recent
%%years~\cite{docker}.
%%
%%When Docker starts a container, it combines read-only layers (and an additional
%%writable layer to store changes) into a single namespace and starts the process
%%declared in the manifest in the new namespace~\cite{docker-driver-eval}.
%
%
%
%Docker images are stored in a centralized \emph{registry} and are pushed to and
%pulled from the registry by clients as needed.
%%
%Docker Hub~\cite{docker-hub} is the most widely used Docker registry
%installation which, according to our estimates, stores more than 400,000
%\emph{public} image repositories comprising a total of 2 million layers.
%%
%This amount is steadily increasing and we observed a linear growth of the
%number of images over a period from June to September 2017.
%
%
%
%While this massive dataset presents challenges to the registry storage
%infrastructure, it also provides opportunities to better understand how
%containers are used in practice.
%%
%Currently, there is little known about the contents, use cases, and workloads
%of production containers.
%%
%In part, this is due to the privacy concerns that organizations and individuals
%have when sharing details of their computing environments.
%%
%However, this knowledge is imperative to design and evaluate novel approaches
%to improve the performance and reliability of containers.
%
%
%
%
%In particular, storage for containers has remained a largely unexplored
%area~\cite{login-container-storage-options}.
%%
%We believe one of the prime reasons is the limited understanding of what data
%is stored inside containers.
%%
%This knowledge can not only help to directly improve the registry and container
%storage infrastructure but also allows to infer container use cases and derive
%representative workloads from that.
%%
%While existing work as focused on various aspects of
%containerization~\cite{slacker, dockervulnerabile, dockerfinder, analysisdockergithub, dockerssd}, analyzing the
%contents of images and layers has not received much attention.
%
%
%
%
%%Though much research was focused on various aspects of
%%containerization~\cite{prev-work-1, prev-work-2, prev-work-3}, storage for containers
%%remains an unexplored territory~\cite{login-container-storage-options}.
%%
%%To start designing a novel storage solution for containers,
%%or to optimize and fairly evaluate existing ones,
%%it is imperative to understand containers' real-world
%%use cases and workloads in sufficient details.
%%
%%Unfortunately, little is known about how containers are used in the real world.
%%
%%In part, this is due to the privacy concerns that organizations and individuals
%%have when sharing details of their computing environments.
%
%
%%Docker images are stored at the centralized \emph{registry} and are pushed to
%%and pulled from the registry by clients as needed. 
%%
%%The most known Docker registry installation is Docker Hub which according to
%%our estimates stores at least 400,000 \emph{public} images that consist of at
%%least 2,000,000 layers.
%
%
%
%
%In this paper we perform the first, comprehensive, large-scale characterization of
%Docker registry contents.
%%
%We downloaded over 50TB of Docker images from Docker Hub and analyzed
%traditional storage properties---\eg, file sizes and types, data compression
%ratios, directory depths---as well as Docker-specific properties---e.g., the number
%of layers per image and the amount of layer sharing.
%%
%%Our insight in this study is that this massive dataset can be used to understand what
%%applications run in containers, how much data they store, and the properties of
%%the data.
%%
%We found, for example:
%\begin{compactenumerate}
%	\item 90\% of the repositories only have a very small pull count (less than 333), which suggests that Docker hub is a good fit for caching few popular repositories or images.
%	\item majority of the images and layers in Docker hub have a smaller size. 90\% of images can be compressed with less than 500 MB and 70\% of images are less than 500 MB even without compression. 90\% of layer can be compressed with less than 63 MB and 77\% of layers are less than 63 MB even without compression.
%	\item Docker images has a great potential for compression to save space.
%	\item 90\% of images have less than 18 layers. Half of images have less than 8 layers. 
%	\item 10\% of layers are referenced more than one image.
%	\item Around 90\% of layers' directory depth is less than 30. 50\% of layers' directory depth is less than ~3.
%	\item Around 30\% of files are ASCII text files. 
%	About 11\% files are gzip compressed files 
%	Interestingly, about 1\% of files are empty. 
%\end{compactenumerate}
%%
%\vcomment{Here we need to stick an example or two of interesting findings. \nancomment{addressed}}
%
%%From our findings, we infer a set of propositions to describe how Docker is
%%used in the real world:
%%\lrcomment{Can we summarize our findings in a few propositions to put here?}.
%%
%%We believe our findings will improve the understanding of containers' data and lay
%%a solid ground for future storage optimizations at clients and registries in
%%Docker and beyond.
%
%After introducing the Docker background~(\S\ref{sec:background}),
%this paper makes the following contributions:
%\begin{compactenumerate}
%  \item We describe a comprehensive methodology to retrieve the complete set of
%  	images stored in Docker Hub~(\S\ref{sec:methodology});
%  \item We perform the first in-depth analysis of container images stored in
%    Docker Hub~(\S\ref{sec:char}).
%%  \item based on our analysis, we formulate propositions on how Docker is currently
%%    used to help guide optimizations and benchmark
%%    workloads~(\S\ref{sec:propositions}).
%\end{compactenumerate}
%
%After discussing related work~(\S\ref{sec:related}),
%the paper concludes~(\S\ref{sec:conclusion}).
%
%%The rest of the paper is organized as follows. We explain
%%relevant Docker details in Section~\ref{sec:background} and our methodology in
%%Section~\ref{sec:methodology}. We present dataset characterization in
%%Section~\ref{sec:results}, describe related work in Section~\ref{sec:related},
%%and conclude in Section~\ref{sec:conclusion}.
