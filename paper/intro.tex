\section{Introduction}

%Virtualization of computational resources is a
%wider spread technique that providides
%in many application fields, ranging
%$from HPC to XXX, to XXX.
%
%Cloud computing relies on compute, storage, and network
%virtualization to provide efficient, elastic, and inexpensive.
%Virtual machines acted as an enabler for Cloud Computing,

For years virtual machines served as a cornerstone of resource virtualization
both on premises and in cloud deployments~\cite{rosenblum2005virtual}.
%
Recently, however, \emph{container-based} virtualization solutions started to
get significant traction.
%
According to polls, over 87\% of enterprises are at various stages of adopting
containers; analysts also predict that by 2020 containers can constitute an
attractive \$2.5 billion market~\cite{container-grow-by2020}.
%
At its core, software container is a set of processes which operating system's
kernel isolate to provide an illusion that they
%the containerized processes
run in the system alone.
%
For instance, Linux performs user, file-system, and other isolations using
namespaces~\cite{man-namespaces}, while performance isolation with the help of
control groups~\cite{kernel-doc-cgroups}.
%
Compared to virtual machines, containers use less memory and storage, are much
faster to start, typically cause less overhead, which explains the increased
interest to this disruptive technology.


Though much research was devoted to containerization in
general~\vcomment{Cite}, storage for containers remains a widely unexplored
territory~\cite{login-container-storage-options}.
%
Before building an optimal solution it is important to understand the
properties of containerized workloads.
%
However, one of the problems with proposing solutions, configuring, and
evaluation is that very little known what user run in containers.
%
It is not easy to get access to the environments where people run containers
and get access to the data.
%
But things are about to change.


Containers are especially popular now, in part, thanks
to Docker technology.
%
Docker combines runtime packaging with containerization
using the concept of multi-layered images.
%
Images are stored at the cenralized registry
and are pulled from the registry when need to be run by a client.
%
Our estimate show that Docker Hub stores around 400,000 images
covering almost 2,000,000 layers---counting only public once.
%
Such a massive set of data allows to understand what applications
people run in containers, what they store in images, and other questions.


In this work we perform and exhaustive characterization of Docker registry
contents.
%
We downloaded over 55TB of Docker images and layers and analyzed layer size,
file size, file type, compression ratio and other distribution.
%
What can we learn from registry contents? How can it help?
%
Use cases: 
- Containerize every user application (like git).
- Containerize services.
- Containerize whole OSes - 
%
Number of images is growing and layers. Currently XXX.
%
A number of companies already provide registry as a service.

Why usefull?  Registry design, overall Docker improvement.
Understand what data people store in general
