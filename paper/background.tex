
\section{Background}

\nancomment{
TODO:\\
1. complete:\\
2. search for reference\\
}\\

Hypervisors based server virtualization technologies (e.g., VMware~\cite{xxx}, Xen~\cite{xxx}, and KVM~\cite{xxx}) have been extensively used by most of cloud platforms such as Amazon EC2, which consists of a virtual machine monitor (VMM) on top of a host operating system that allows dynamically partitioning of a machine and sharing the available physical resources such as CPU, storage, memory and I/O devices to support the concurrent execution of multiple guest operating systems instances within virtual machines (VMs) and provide users with benefits ranging from application isolation through server consolidation to improve disaster recovery and faster server provisioning~\cite{xxx}.

Nevertheless, hypervisor-based virtualization has a high performance overhead because of execution time overhead caused by executing privileged instructions and memory overhead caused by running multiple VMs. Guest OSs are normally executed at a reduced privilege level~\cite{}. Hypervisor intercepts traps from guest OSs and emulates the trapping instructions, which incurs execution time overheads, specially for applications which relies on I/O operations since I/O interrupt overhead is amplified for nested virtual machine. Memory overhead includes space reserved for the VMs buffer and various virtualization data structures, such as shadow page tables~\cite{}, which increases with the number of virtual CPUs and the configured memory for the guest OSs~\cite{}. 

Recent container-based virtualization (such as Linux Containers(LXC)~\cite{xxx}, OpenVZ~\cite{bibid}, and Docker~\cite{}) emerges as a lightweigh virtualization, which promises a near-native performance. As opposed to virtual machines (VMs), container based virtualization works at operating system level and do not emulate another operating system. In this case, all the virtual instances share a single operating system kernel, which significantly reduces the overhead imposed through VMs. LXC offers isolation (of PIDs, IPCs, mount pints, and network) through (PID and network) \textit{namespaces} while manages resource and controls processes via \textit{cgroups}~\cite{}. 

Docker container is a new popular container-based virtualization technology that extends LXC with higher level APIs and additional functionality. It also uses namespaces to isolate applications inside containers. Moreover, Docker incorporates copy-on-write union filesystems (UnionFS) to avoid duplication and enable versioning. It couples the above two components with a number of features, like portability, re-use, and reproducibility.

%Docker is an open source project that automates the deployment of applications inside Linux Containers, and provides the capability to package an application with its runtime dependencies into a container. It provides a Docker CLI command line tool for the lifecycle management of image-based containers. Linux containers enable rapid application deployment, simpler testing, maintenance, and troubleshooting while improving security. 

%, and  that make it developer-centric (and therefore distinct from traditional virtual machines that attempt to hew as much as possible to the metaphor of machine): like deployment 

%AuFS (Advanced Multi-Layered Unification Filesystem) as a filesystem for containers. AuFS is a layered filesystem that can transparently overlay one or more existing filesystems. When a process needs to modify a file, AuFS creates a copy of that file. AuFS is capable of merging multiple layers into a single representation of a filesystem. This process is called copy-on-write. 
 
%Docker using a high-level API that provides a lightweight virtualization solution to run processes in isolation. Docker is developed in the Go language and utilizes LXC, cgroups, and the Linux kernel itself. Since it’s based on LXC, a Docker container does not include a separate operating system; instead it relies on the operating system’s own functionality as provided by the underlying infrastructure. So Docker acts as a portable container engine, packaging the application and all its dependencies in a virtual container that can run on any Linux server.
 
% packaging and delivery technology, combining lightweight application isolation with the flexibility of image-based deployment methods. 
 
%an extension of LXC’s capabilities that provides higher level APIs and functionality as a portable container engine. It aims to improve reproducibility of applications by enabling bundling of container contents into a single object that can be deployed across machines.

%Docker is an open source project that automates the deployment of applications inside Linux Containers, and provides the capability to package an application with its runtime dependencies into a container. It provides a Docker CLI command line tool for the lifecycle management of image-based containers. Linux containers enable rapid application deployment, simpler testing, maintenance, and troubleshooting while improving security. 

% Linux Containers LXC, a user-space control package for Linux Containers, constitute the core of Docker. 
 
 %Docker harnesses some powerful kernel-level technology and puts it at our fingertips. The concept of a container in virtualization has been around for several years, but by providing a simple tool set and a unified API for managing some kernel-level technologies, such as LXCs (LinuX Containers), cgroups and a copy-on-write filesystem, Docker has created a tool that is greater than the sum of its parts. The result is a potential game-changer for DevOps, system administrators and developers.
 
 %Docker provides tools to make creating and working with containers as easy as possible. Containers sandbox processes from each other. For now, you can think of a container as a lightweight equivalent of a virtual machine.
 
\subsection{Docker \& Docker container}

%Docker is an open platform for developers and system administrators to build, ship, and run distributed applications using Docker Engine, a portable, lightweight runtime and packaging tool, and Docker Hub, a cloud service for sharing applications and automating workflows. The main advantage is that,
%Docker allows packaging an application with its dependencies into a standardized, self-contained unit (a so-called container), which can be used for software development and to run the application on any system.
%Containers are an abstraction at the app layer that packages code and dependencies together. 
 
\nancomment{
	1. TODO: add a docker architecture pic\\
}\\
%how container isolate.
Docker containers create a wrapped, controlled environment on the host machine in which applications can be run in isolated manner via two main Linux kernel features -- kernel namespaces which are used to split the view that processes have of the system and control groups (cgroups) that restricts the resource usage of a process or group of processes. Currently, Linux kernel provides six different namespaces, PID, IPC, NET, MNT, UTS, and USER for process IDs, IPC requests, networking, file-system mount points, host names, and user IDs~\cite{xxx}~\cite{xxx}. Controlled resources include CPU shares, RAM, network bandwidth, and disk I/O.

%how container deameon. 

As Figure~\ref{xxx} shows, Docker ecosystem includes various components, i.e., Docker daemon, Docker container, Docker image, and Docker Hub. Docker Deamon, known as Docker engine, can create images from Dockerfiles (through docker build), launch containers (through docker run), and fetch non-local images from Docker registry as well as publish new images to Docker registry such as Docker Hub (through docker pull or docker push). It controls isolation levels of containers including cgroups, namespaces, capabilities restrictions, and SELinux/Apparmorprofiles, monitor them to trigger actions such as restart, and spawn shells into running containers for administration purposes. 

 
 
\subsection{Docker image \& Docker storage drivers}

\subsubsection{Docker image}

% what is image containning
Docker image is an immutable and `executable' file that is essentially a snapshot of a container. Docker images packages an application only with its runtime dependencies, such as binaries, and libraries to maintain lightweight characteristics. Images are read-only copies of file system data. All modifications to the container that add new or modify existing data are stored in this writable layer. When the container is deleted, the writable layer is also deleted. The underlying image remains unchanged. Because each container has its own writable container layer, and all changes are stored in this container layer, multiple containers can share access to the same underlying image and yet have their own data state~\cite{}. 
% how to build, relation to container

There are two methods to build a Docker image: The first method is called interactive building which is carried out by starting a base image as a container (via `Docker run'), running commands to install the desired software on the running container, then committing the changes creating a new image on the local Docker repository~\cite{}. The second method is called building from a Dockerfile which is carried out by writing a Dockerfile. A Dockefile is a script file that contains all the commands one would normally execute manually in order to build an image. Dockerfile starts by loading a base image, followed by the list of Docker formatted commands to install the desired software. The image is built via `docker build'. 

Docker images are composed of a set of individual layers along with metadata in the JavaScript Object Notation (JSON) format called manifest. Each layer contains the data modifications relative to the previous layer, starting from a base layer/image (typically, a lightweight Linux distribution). Each layer has a parent, except for the base layers/images, which are the roots of the trees. This structure avoid Docker pulling redundant layers. The manifest contains

%\begin{enumerate}
	%\item Layers.
	%\item Manifest.
	%\item Config file.
%\end{enumerate}

\subsubsection{Copy-on-write storage}

% what is .., benefit

The data management of container is superintend either by Docker storage drivers (e.g. AUFS, OverlayFS, Btrfs, etc) or by docker data volumes. Docker daemon can only run one storage driver and all containers created by that daemon instance use the same storage driver. Storage driver operate with copy-on-write technique, which thus provide more advantages for read intensive applications. Docker volume is mechanism to automatically provide data persistence for containers. A volume is a directory or a file that can be mounted directly inside the container. The I/O operations through this mount path are independent of storage driver and executed directly on the host. 

Docker provides a variety of pluggable storage drivers that are based on Linux filesystem or volume manager, including advanced multi-layered unification filesystem (aufs), B-tree file system (Btrfs), virtual filesystem switch (VFS), device mapper, or OverlayFS. Aufs is a fast reliable unification file system with some new features like writable branch balancing. Btrfs
(B-tree file system) is a modern CoW file system which implements many advanced features for fault tolerance, repair
and easy administration. Overlayfs is another modern union file system which has a simpler design and is potentially faster
than Aufs.

Device mapper is a Linux kernel component; it provides a mechanism for mapping physical block devices onto virtual block devices. These mapped devices can be used as logical volumes. Device mapper provides a generic way for creating such mappings. Device mapper maintains a table which defines device mappings. The table specifies how to map each range of logical sectors of the device.

%BTRFS is a Linux file system which has a poten-
%tial of replacing the current Linux default file system,

%The start value for the first line is always zero. For other
%lines, start + length of the previous line should be equal
%to start value of the current line. Device mapper sizes are
%always specified in 512 bytes sectors. There are different
%types of mapping targets linear, striped, mirror, snapshot,
%snapshot-origin, etc.

BTRFS (also knows as ”butter FS”) is basically a copy on write file system. Copy-on-write(CoW) means it does not update the data ever.[8] Instead, it cre-
ates a new copy of that part of data which is stored some-
where else on the disk keeping the old part as it is. Any-
one with a decent file systems knowledge would under-
stand that CoW requires more space because it stores the
old copies of data as well. Also, it has a problem of frag-
mentation. Then how can a CoW file system be used as a
default Linux file system? Wouldn’t that reduce the per-
formance? No need to mention the storage space prob-
lem. Let’s dive into BTRFS to understand why it has
become so popular.[9]
The primary design goal of BTRFS was to develop
a generic file system which can perform well with any
use cases and workload. Most of the file systems per-
form well for a particular specific file system benchmark,
and the performance is no that great for other scenarios.
Apart from this BTRFS also supports snapshots, cloning,
and RAID (Level 0, 1, 10, 5, 6). This is more than any-
one has bargained for from a file system before. One can
understand the design complexity because Linux file sys-
tems are deployed on all kinds of devices from computers
and smart phones to small embedded devices.[10]
The BTRFS layout is represented with B-trees, more
like a forest of B-trees. These are copy-on-write friendly
B-trees. As CoW file systems require a little more disk
space, in general, BTRFS has a very sophisticated mech-
anism for space reclamation. It has a garbage collector
which makes use of reference counting to reclaims un-
used disk space. For data integrity part, BTRFS uses
check sums.

%The commonly used storage drivers are 

% different types

%\begin{enumerate}
%	\item aufs.
%	\item zfs.
%	\item overlay/overlay2.
%	\item devicemapper.
%\end{enumerate}

%\subsubsection{Storage driver}

% The storage driver controls how images and containers are stored and managed on Docker host using a pluggable architecture. 

%\begin{enumerate}
%	\item aufs.
%	\item zfs.
%	\item overlay/overlay2.
%	\item devicemapper.
%\end{enumerate}

%\subsubsection{}

\subsection{Docker Registry}

The Docker Registry, known as Docker Hub, allows users push their Docker images to it and pulling Docker images from it.The repositories in Docker Hub is either public or private. All the non-repositories'names are in ``$\langle namespace\rangle/\langle repository name \rangle$" format, where~\textit{namespace} is the user name. The official repositories'names only contain ``repository name".



%The Registry is a stateless, highly scalable server side application that stores and lets you distribute Docker images.

%\begin{enumerate}
%	\item Registry versions.
%	\item Content addressability.
%	\item Pulling images/pushing images.
%\end{enumerate}

%\subsection{Current public registries}
